# Server
PORT=5000
NODE_ENV=development

# MongoDB
MONGODB_URI=mongodb+srv://mango_db:Bsm88cluster@clusterbirappa.mrc95e4.mongodb.net/?appName=ClusterBirappa

# File Upload
MAX_FILE_SIZE_MB=5
UPLOAD_DIR=uploads

# Rate Limiting
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100

# ═══════════════════════════════════════════════════════════════════════════════
# AI PROVIDER CONFIGURATION
# ═══════════════════════════════════════════════════════════════════════════════

# Choose your AI provider: 'gemini', 'groq', 'ollama', or 'mock'
AI_PROVIDER=gemini

# ─── GOOGLE GEMINI (RECOMMENDED - FREE & FAST) ────────────────────────────────
# Sign up: https://aistudio.google.com/app/apikey
# Free tier: 15 requests/minute, 1M requests/day
# Best for: Production use, fast responses, reliable

GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.5-flash
# Options: gemini-2.5-flash (faster), gemini-2.5-pro (more capable)

# ─── GROQ (FAST & FREE) ───────────────────────────────────────────────────────
# Sign up: https://console.groq.com/
# Free tier: 30 requests/minute, extremely fast inference
# Best for: Real-time applications, fast responses

GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.3-70b-versatile
# Options: llama-3.3-70b-versatile, llama-3.1-8b-instant, mixtral-8x7b-32768

# ─── OLLAMA (LOCAL, FREE, NO API KEY) ────────────────────────────────────────
# Install: https://ollama.ai/download
# Pull model: ollama pull llama3.1
# Run: ollama serve (localhost:11434)
# Best for: Privacy, no API costs, offline use

OLLAMA_MODEL=llama3.1
OLLAMA_HOST=http://localhost:11434
# Options: llama3.1, mistral, codellama, gemma

# ─── MOCK (NO API KEY, FOR TESTING) ───────────────────────────────────────────
# Uses keyword matching and heuristics
# Best for: Development, testing, no costs
# No additional configuration needed
